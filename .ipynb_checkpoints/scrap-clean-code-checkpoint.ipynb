{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tickers.txt\") as f:\n",
    "    data=f.read()\n",
    "    tickers = data.strip().split(\"\\n\")\n",
    "    \n",
    "#print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "from xml.etree.cElementTree import XML\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGS\n",
    "\n",
    "\n",
    "\n",
    "month_d = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "#searchTerms = r'JP Morgan'\n",
    "searchTermsList = [r'oracle', r'morgan stanley']\n",
    "searchTermsList = map(lambda x: \"ticker({})\".format(x) ,tickers[:10])\n",
    "url = r'https://libproxy.usc.edu/login?url=http://www.nexisuni.com'\n",
    "# url = r'http://libguides.usc.edu/go.php?c=9232127'\n",
    "username = 'junhuihe'\n",
    "password = 'ivy930322jasper951128'\n",
    "# username = 'MyUSCPassUsername'\n",
    "# password = 'MyUSCPassWord'\n",
    "#root = r'/Users/jasper/Documents/scrape_help/LexisNexis-Scraping'\n",
    "root = os.getcwd() + r'/browser'\n",
    "path_to_chromedriver = root + r'/operadriver'\n",
    "path_to_ffdriver = root + r'/geckodriver'\n",
    "\n",
    "#download_folder = root + r'\\{}\\download'.format(searchTerms)\n",
    "# path_to_chromedriver = root + r'\\chromedriver'\n",
    "# download_folder = root + r'\\download'\n",
    "# dead_time = 300\n",
    "dead_time = 300\n",
    "\n",
    "\n",
    "## NEW PARAMS\n",
    "__default_enddate = \"December.2014\"\n",
    "\n",
    "__default_startdate = \"January.2001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(\"headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOWNLOAD METHOD\n",
    "\n",
    "\n",
    "def download_file(searchTerms, download_folder, url = url, username = username, \\\n",
    "                  dead_time = dead_time, path_to_chromedriver=path_to_chromedriver, enddate=__default_enddate):\n",
    "    while True:\n",
    "        endmonth,endyear = enddate.split(\".\")\n",
    "        \n",
    "        startmonth,startyear = __default_startdate.split(\".\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            __DRIVER = \"FF\" #  OP -opera\n",
    "\n",
    "            if __DRIVER==\"FF\":\n",
    "                #### FIREFOX OPTIONS\n",
    "                \n",
    "\n",
    "                profile = webdriver.FirefoxProfile()\n",
    "                profile.set_preference(\"browser.download.folderList\", 2)\n",
    "                profile.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "                profile.set_preference(\"browser.download.dir\", download_folder + r'/temp')\n",
    "                profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/x-zip-compressed\")\n",
    "                \n",
    "                #make headless\n",
    "                from selenium.webdriver.firefox.options import Options\n",
    "                __options = Options()\n",
    "                __options.headless = os.path.isfile(\"headless\")\n",
    "                browser = webdriver.Firefox(executable_path = path_to_ffdriver,firefox_options=__options,firefox_profile=profile)\n",
    "\n",
    "\n",
    "            elif __DRIVER==\"OP\":\n",
    "                ### CHROME/OPERA\n",
    "                \n",
    "\n",
    "                # chromeOptions = webdriver.ChromeOptions()\n",
    "                prefs = {\"download.default_directory\" : download_folder + r'/temp'}\n",
    "                # chromeOptions.add_argument('headless')\n",
    "                chromeOptions = webdriver.ChromeOptions()\n",
    "                # chromeOptions.add_argument(\"--window-size=1800,1000\")\n",
    "                # chromeOptions.add_argument(\"--disable-extensions\")\n",
    "                # chromeOptions.add_argument(\"--proxy-server='direct://'\")\n",
    "                # chromeOptions.add_argument(\"--proxy-bypass-list=*\")\n",
    "                # chromeOptions.add_argument(\"--start-maximized\")\n",
    "                # chromeOptions.add_argument('--headless')\n",
    "                # chromeOptions.add_argument('--disable-gpu')\n",
    "                # chromeOptions.add_argument('--disable-dev-shm-usage')\n",
    "                # chromeOptions.add_argument('--no-sandbox')\n",
    "                # chromeOptions.add_argument('--ignore-certificate-errors')\n",
    "                # chromeOptions.add_argument('no-sandbox')\n",
    "                chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "                browser = webdriver.Chrome(executable_path = path_to_chromedriver, options=chromeOptions)\n",
    "\n",
    "                        \n",
    "            print(\"scraping starts\")\n",
    "            browser.set_window_size(1800, 1000)\n",
    "            #browser.set_window_size(900, 500)\n",
    "            #Login\n",
    "            browser.get(url)\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"login in time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_id('username').send_keys(username)\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            browser.find_element_by_id('password').send_keys(password)\n",
    "            browser.find_element_by_xpath('//*[@id=\"loginform\"]/div[4]/button').click()\n",
    "            print(\"{} login in successfully\".format(username))\n",
    "            # Get Page Info\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"redirect to search page time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"searchTerms\"]').send_keys(searchTerms)\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            browser.find_element_by_xpath('//*[@id=\"mainSearch\"]').click()\n",
    "            # Sort by Date and narrow by some conditions\n",
    "            #publication type\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting publication type conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonpublicationtype\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            try:\n",
    "                browser.find_element_by_class_name('more').click()\n",
    "            except:\n",
    "                pass\n",
    "            while True:\n",
    "                try:\n",
    "                    for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Newswires & Press Releases')]\"):\n",
    "                        try:\n",
    "                            ele.click()\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            print(\"publication type is set\")\n",
    "            #source\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting source conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonsource\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            try:\n",
    "                # browser.find_element_by_xpath('//*[@id=\"refine\"]/ul[1]/li[7]/button').click()\n",
    "                browser.find_element_by_class_name('more').click()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Business Wire')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                #browser.find_element_by_text_link('The Associated Press').click()\n",
    "                #browser.find_elements_by_xpath(\"//*[contains(text(), 'My Button')]\").click()\n",
    "                print(\"source is set\")\n",
    "            except:\n",
    "                pass\n",
    "            # timeline start\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting timeline time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"refine\"]/button[2]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            if int(browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[1]/input').get_attribute('value').split('/')[-1]) <= 2001:\n",
    "                browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[1]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectyeartimeline\"]').click()\n",
    "                #browser.find_element_by_xpath('//*[@id=\"datepicker\"]/h3/div[2]/ol/li[33]/button').click()\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+startyear+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+startmonth+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[2]/td[3]/button').click()\n",
    "            # timeline end\n",
    "            if int(browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[2]/input').get_attribute('value').split('/')[-1]) >= 2019:\n",
    "                browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[2]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectyeartimeline\"]').click()\n",
    "                #for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '2014')]\"):\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+endyear+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                #for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'December')]\"):\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+endmonth+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                #browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                #browser.find_element_by_xpath('//*[@id=\"datepicker\"]/h3/div[1]/ol/li[12]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button').click()\n",
    "            # click ok\n",
    "            browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/button').click()\n",
    "            start_time = time.time()\n",
    "            print(\"time range is set\")\n",
    "            # subject\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting subject conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonsubject\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            while True:\n",
    "                try:\n",
    "                    for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Business News')]\"):\n",
    "                        try:\n",
    "                            ele.click()\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            print(\"subject is set\")\n",
    "\n",
    "            #sort by time\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"sorting by time time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[2]/li/div/button').click()\n",
    "                    break\n",
    "                except WebDriverException:\n",
    "                    time.sleep(1)\n",
    "            browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[2]/li/div/div/button[4]').click()\n",
    "            #N_temp = how many articles eg: News (10,000+)\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"get number of articles time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    N_temp = browser.find_element_by_xpath('//*[@id=\"content\"]/header/h2/span').text\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            total_number = int(''.join(re.findall(r'[0-9]', N_temp)))\n",
    "            print(\"we'll scrape down {} files related to '{}'\".format(total_number, searchTerms))\n",
    "            print(\"TOTAL NUMBER ->\",total_number)\n",
    "            \n",
    "            if total_number > 100:\n",
    "                # updated - we now use the page numbers directly from the bottom pagination\n",
    "                total_page = browser.find_element_by_xpath('/html/body/main/div/main/div[2]/div/div[2]/div[2]/form/div[2]/nav/ol/li[6]/a').text\n",
    "                total_page = int(total_page)\n",
    "            else:\n",
    "                total_page = int(np.ceil(total_number/10))\n",
    "                \n",
    "            print(\"TOTAL PAGES ->\", total_page)\n",
    "            \n",
    "            #time.sleep(100)\n",
    "            \n",
    "            file_digit = len(str(total_page)) * 2 + 1\n",
    "            for page in range(1, total_page + 1):\n",
    "                time.sleep(2)\n",
    "                date = browser.find_element_by_xpath('//*[@id=\"content\"]/div[2]/form/div[2]/ol/li[1]/div/div[1]/dl/dd[4]/a').text\n",
    "                month, year = date.split(',')\n",
    "                month = month_d[month[:3]]\n",
    "                new_folder = download_folder + r'/{}/{}{}'.format(searchTerms, month.strip(), year.strip())\n",
    "                #new_folder = download_folder + r'\\{}-{}\\{}'.format( month.strip(), year.strip(),searchTerms)\n",
    "                # =============================================================================\n",
    "                #     If the file already exists. Go to next page.\n",
    "                # =============================================================================\n",
    "                if os.path.isfile(new_folder + '/'  + (str(page) + '_' + str(total_page)).zfill(file_digit) +  '.ZIP'):\n",
    "                #if os.path.isfile(download_folder + '/'  + (str(page) + '_' + str(total_page)).zfill(file_digit) +  '.ZIP'):\n",
    "\n",
    "                    print('exist: ' + str(page) + '_' + str(total_page) +  '.ZIP')\n",
    "                    if page < total_page:\n",
    "                        try:\n",
    "                            start_time = time.time()\n",
    "                            while True:\n",
    "                                if time.time() - start_time > dead_time:\n",
    "                                    raise Exception()\n",
    "                                WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.LINK_TEXT , str(page + 1))))\n",
    "                                browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                        except WebDriverException:\n",
    "                            time.sleep(3)\n",
    "                            continue\n",
    "                # =============================================================================\n",
    "                # Wait the all checkbox to be clickable\n",
    "                # =============================================================================\n",
    "                while True:\n",
    "                    print(\"here\")\n",
    "                    try:\n",
    "                        ele = browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input')\n",
    "                        print(ele)\n",
    "                        # if browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input').get_attribute('checked') != 'true':\n",
    "                        #     browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input').click()\n",
    "                        # print(ele.get_attribute('checked'))\n",
    "                        # if not ele.get_attribute('checked'):\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except WebDriverException:\n",
    "                        time.sleep(1)\n",
    "                # =============================================================================\n",
    "                #   Wait the IncludeAttachments button to be clickable.  otherwise re-click download buttom\n",
    "                # =============================================================================\n",
    "                # try:\n",
    "                #     start_time = time.time()\n",
    "                #     while True:\n",
    "                #         if time.time() - start_time > dead_time:\n",
    "                #             raise Exception()\n",
    "                #         elm = browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[4]/ul/li[3]/button')\n",
    "                #         elm.click()\n",
    "                # except WebDriverException:\n",
    "                #     pass\n",
    "                while True:\n",
    "                    try:\n",
    "                        browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[4]/ul/li[3]/button').click()\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    if time.time() - start_time > dead_time:\n",
    "                        raise Exception()\n",
    "                    try:\n",
    "                        browser.find_element_by_xpath('//*[@id=\"DocumentsOnly\"]').click()\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                browser.find_element_by_xpath('//*[@id=\"IncludeAttachments\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"Docx\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"SeparateFiles\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"FileName\"]').clear()\n",
    "                browser.find_element_by_xpath('//*[@id=\"FileName\"]').send_keys((str(page) + '_' + str(total_page)).zfill(file_digit))\n",
    "                # =============================================================================\n",
    "                #     After downloading Close the pop up window. LexisNexis only allows 5 cocurrent windows\n",
    "                # =============================================================================\n",
    "                \n",
    "                before = browser.window_handles[0]\n",
    "                # browser.find_element_by_xpath('/html/body/aside/footer/ul/li[1]/input').click()\n",
    "                browser.find_element_by_xpath('/html/body/aside/footer/div/button[1]').click()\n",
    "                # print('here')\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    try:\n",
    "                        after = browser.window_handles[1]\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                browser.switch_to.window(after)\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    if time.time() - start_time > dead_time:\n",
    "                        raise Exception()\n",
    "                    if  browser.find_elements_by_link_text((str(page) + '_' + str(total_page)).zfill(file_digit)):\n",
    "                        break\n",
    "                \n",
    "                ### CHECK DOWNLOAD COMPLETED BEFORE WE CLOSE DOWNLOAD WINDOW\n",
    "                start_time = time.time()\n",
    "                ### wait maximum 30s for download\n",
    "                while time.time() - start_time < 30:\n",
    "                    try:\n",
    "                        if \"Delivery Complete\" in browser.find_element_by_xpath('/html/body/main/div/div[2]/section/h1').text:\n",
    "                            print(\"-> Closing the Download Window...\")\n",
    "                            time.sleep(1)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"-> Waiting for Download to be complete...\")\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(\"Exception @ waiting download to complete -->\",e)\n",
    "                        time.sleep(1)\n",
    "                    finally:\n",
    "                        time.sleep(1)\n",
    "        \n",
    "                        \n",
    "                #time.sleep(100)\n",
    "                \n",
    "                browser.close()\n",
    "                browser.switch_to.window(before)\n",
    "                print(browser.title)\n",
    "                time.sleep(2)\n",
    "                old_folder = download_folder + r'/temp'\n",
    "                os.chdir(old_folder)\n",
    "                if not os.path.isdir(new_folder):\n",
    "                    os.makedirs(new_folder)\n",
    "                for f in os.listdir():\n",
    "                    shutil.move(old_folder + r'/{}'.format(f), new_folder + r'/{}'.format(f))\n",
    "                print('finishing page' + str(page) + '_' + str(total_page)  )\n",
    "                # =============================================================================\n",
    "                #     Go to the next page. Have to check the next page link is clickable\n",
    "                # =============================================================================\n",
    "                if page < total_page:\n",
    "                    try:\n",
    "                        browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                        start_time = time.time()\n",
    "                        while True:\n",
    "                            if time.time() - start_time > dead_time:\n",
    "                                raise Exception()\n",
    "                            browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                    except WebDriverException:\n",
    "                        time.sleep(3)\n",
    "                        pass\n",
    "                else:\n",
    "                    print('FINISHED!')\n",
    "                    #sys.exit()\n",
    "                    return 7\n",
    "                # except Exception:\n",
    "                #     print('restarting')\n",
    "                #     continue\n",
    "            print('Finished')\n",
    "            return 7\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Main exception->\",e)\n",
    "            print(traceback.format_exc())\n",
    "            print(\"restarting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITIES AND HELPERS\n",
    "\n",
    "\n",
    "\n",
    "def unzip(download_folder):\n",
    "    if not os.path.exists(download_folder + '/' + 'unzipped'):\n",
    "        os.makedirs(download_folder + '/' + 'unzipped')\n",
    "    for filename in os.listdir(download_folder):\n",
    "        if not filename.endswith('.ZIP'):\n",
    "            continue\n",
    "        zip_ref = zipfile.ZipFile(download_folder +  '/' + filename, 'r')\n",
    "        zip_ref.extractall(download_folder + '/' + 'unzipped')\n",
    "        if len(zip_ref.namelist()) != 11:\n",
    "            print('missing document at ' + filename)\n",
    "        zip_ref.close()\n",
    "        print('unzipping ' + filename)\n",
    "\n",
    "\n",
    "def create_index(download_folder, searchTerms):\n",
    "    def get_docx_text(path):\n",
    "        WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "        PARA = WORD_NAMESPACE + 'p'\n",
    "        TEXT = WORD_NAMESPACE + 't'\n",
    "        \"\"\"\n",
    "        Take the path of a docx file as argument, return the text in unicode.\n",
    "        \"\"\"\n",
    "        document = zipfile.ZipFile(path)\n",
    "        xml_content = document.read('word/document.xml')\n",
    "        document.close()\n",
    "        tree = XML(xml_content)\n",
    "\n",
    "        paragraphs = []\n",
    "        for paragraph in tree.getiterator(PARA):\n",
    "            texts = [node.text\n",
    "                     for node in paragraph.getiterator(TEXT)\n",
    "                     if node.text]\n",
    "            if texts:\n",
    "                paragraphs.append(''.join(texts))\n",
    "\n",
    "        return '\\n\\n'.join(paragraphs)\n",
    "    def get_docx_hyperlink(path):\n",
    "        document = Document(path)\n",
    "        rels = document.part.rels\n",
    "        link = []\n",
    "        for rel in rels:\n",
    "            if rels[rel].reltype == RT.HYPERLINK:\n",
    "                link.append(rels[rel]._target)\n",
    "        return pd.Series(link)\n",
    "    def find_between(s, first, last):\n",
    "        list = []\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    start = s.index( first ) + len( first )\n",
    "                    end = s.index( last, start )\n",
    "                    list.append( s[start:end])\n",
    "                    s = s.replace(first + s[start:end] + last,'')\n",
    "                except:\n",
    "                    break\n",
    "            return list\n",
    "        except ValueError:\n",
    "            return \"\"\n",
    "\n",
    "    index = pd.DataFrame(({'Title':{},'Link':{}}))\n",
    "    for filename in os.listdir(download_folder + '/' + 'unzipped'):\n",
    "        if filename.find(\"doclist\") == -1:\n",
    "            continue\n",
    "        text = get_docx_text(download_folder + '/' + 'unzipped/' + filename)\n",
    "        link = get_docx_hyperlink(download_folder + '/' + 'unzipped/' + filename).loc[0]\n",
    "        content = '<start>' + re.sub(r'.*Documents \\(\\d*\\)', '',text.replace('\\n',' ')).replace(\\\n",
    "              'Client/Matter: -None-  Search Terms: '+ searchTerms + '  Search Type: Terms and Connectors   Narrowed by:   Content Type  Narrowed by  News  -None-',\\\n",
    "              '<end><start>')\n",
    "        content_list = pd.Series(find_between(content, '<start>', '<end>'))\n",
    "        content_list = content_list.str[5:]\n",
    "        index = index.append(pd.DataFrame({'Title':content_list,'Link':link}),ignore_index = True)\n",
    "    index = index.reset_index()\n",
    "    index['index'] = index.index + 1\n",
    "    index.to_csv(download_folder + '/index.csv', index=False)\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX AND SCRIPT SUPERVISOR HELPERS\n",
    "\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "# SET CONFIG VARIABLES\n",
    "__download_folder = os.path.join(root,\"download\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_last_download_date(__searchterm):\n",
    "    # check if folder exists\n",
    "    if __searchterm in os.listdir(__download_folder):\n",
    "        __folder_searchterm = os.path.join(__download_folder,__searchterm)\n",
    "\n",
    "        already_downloaded = os.listdir(__folder_searchterm)\n",
    "\n",
    "        if len(already_downloaded)==0:\n",
    "            __enddate = __default_enddate\n",
    "\n",
    "        else:\n",
    "\n",
    "            # sort on datetime\n",
    "            already_downloaded = sorted(already_downloaded, key=dateutil.parser.parse)\n",
    "\n",
    "\n",
    "            latest = already_downloaded[0]\n",
    "\n",
    "\n",
    "            # empty the latest folder\n",
    "            __folder_latest = os.path.join(__folder_searchterm,latest)\n",
    "\n",
    "            #crawl subdirs in side latest folder and delete\n",
    "            for subfolder in os.listdir(__folder_latest):\n",
    "                this_path = os.path.join(__folder_latest,subfolder)\n",
    "                print(\"DELETING --->\",this_path)\n",
    "                if os.path.isdir(this_path):\n",
    "                    shutil.rmtree(__folder_latest)\n",
    "                else:\n",
    "                    os.remove(this_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            __enddate = dateutil.parser.parse(latest).strftime(\"%B.%Y\")\n",
    "\n",
    "    else:\n",
    "        __enddate = __default_enddate\n",
    "        \n",
    "    return __enddate\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETING ---> /home/sampad/Desktop/shuyi/CODE/browser/download/ticker(ORCL)/112014/04_61.ZIP\n",
      "DELETING ---> /home/sampad/Desktop/shuyi/CODE/browser/download/ticker(ORCL)/112014/05_61.ZIP\n",
      "\n",
      "RESUMING TILL END DATE --> November.2014\n",
      "\n",
      "\n",
      "scraping starts\n",
      "junhuihe login in successfully\n",
      "publication type is set\n",
      "source is set\n",
      "Main exception-> Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-8194b8a836b3>\", line 191, in download_file\n",
      "    browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button').click()\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 394, in find_element_by_xpath\n",
      "    return self.find_element(by=By.XPATH, value=xpath)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "\n",
      "restarting\n",
      "scraping starts\n",
      "junhuihe login in successfully\n",
      "publication type is set\n",
      "source is set\n",
      "Main exception-> Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-8194b8a836b3>\", line 191, in download_file\n",
      "    browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button').click()\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 394, in find_element_by_xpath\n",
      "    return self.find_element(by=By.XPATH, value=xpath)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "\n",
      "restarting\n",
      "scraping starts\n",
      "junhuihe login in successfully\n",
      "publication type is set\n",
      "source is set\n",
      "Main exception-> Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-8194b8a836b3>\", line 191, in download_file\n",
      "    browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button').click()\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 394, in find_element_by_xpath\n",
      "    return self.find_element(by=By.XPATH, value=xpath)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/sampad/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button\"}\n",
      "  (Session info: chrome=81.0.4044.129)\n",
      "  (Driver info: operadriver=81.0.4044.113 (e3225dafb0475864a1812a374d73a92e391635ac-refs/branch-heads/4044@{#936}),platform=Linux 4.19.0-6-amd64 x86_64)\n",
      "\n",
      "\n",
      "restarting\n",
      "scraping starts\n"
     ]
    }
   ],
   "source": [
    "### MAIN\n",
    "\n",
    "\n",
    "try:\n",
    "    if \"SEARCHTERM\" in os.environ:\n",
    "        searchTermsList = [os.environ[\"SEARCHTERM\"]]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Have you suppied ENVIRONMENT VAR -> SEARCHTERM\")\n",
    "    #exit(0)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for searchTerms in searchTermsList:\n",
    "        \n",
    "        __enddate = get_last_download_date(searchTerms)\n",
    "        \n",
    "        if(__enddate==__default_enddate):\n",
    "            print(\"\\nSTARTING FULL DOWNLOAD TILL ---> %s\\n\\n\" % __enddate )\n",
    "        else:\n",
    "            print(\"\\nRESUMING TILL END DATE --> %s\\n\\n\" % __enddate)\n",
    "            \n",
    "        \n",
    "\n",
    "        val = download_file(searchTerms = searchTerms, download_folder = __download_folder, enddate=__enddate )\n",
    "        \n",
    "        print(\"Download Method return code ->\",val)\n",
    "        ## SAVE PROGRESS IF FINISHED\n",
    "        if val==7:\n",
    "            print(\"-> Writing to done.txt --> \",searchTerms)\n",
    "            with open(os.path.join(root,\"..\",\"done.txt\"),'a+') as g:\n",
    "                g.write(searchTerms+\"\\n\")\n",
    "        \n",
    "        exit(0)\n",
    "        \n",
    "    # unzip()\n",
    "    # create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
