{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tickers.txt\") as f:\n",
    "    data=f.read()\n",
    "    tickers = data.strip().split(\"\\n\")\n",
    "    \n",
    "#print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "from xml.etree.cElementTree import XML\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGS\n",
    "\n",
    "\n",
    "\n",
    "month_d = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "#searchTerms = r'JP Morgan'\n",
    "searchTermsList = [r'oracle', r'morgan stanley']\n",
    "searchTermsList = map(lambda x: f'ticker({x})' ,tickers[:10])\n",
    "url = r'https://libproxy.usc.edu/login?url=http://www.nexisuni.com'\n",
    "# url = r'http://libguides.usc.edu/go.php?c=9232127'\n",
    "username = 'junhuihe'\n",
    "password = 'ivy930322jasper951128'\n",
    "# username = 'MyUSCPassUsername'\n",
    "# password = 'MyUSCPassWord'\n",
    "#root = r'/Users/jasper/Documents/scrape_help/LexisNexis-Scraping'\n",
    "root = os.getcwd() + r'/browser'\n",
    "path_to_chromedriver = root + r'/operadriver'\n",
    "path_to_ffdriver = root + r'/geckodriver'\n",
    "\n",
    "#download_folder = root + r'\\{}\\download'.format(searchTerms)\n",
    "# path_to_chromedriver = root + r'\\chromedriver'\n",
    "# download_folder = root + r'\\download'\n",
    "# dead_time = 300\n",
    "dead_time = 300\n",
    "\n",
    "\n",
    "## NEW PARAMS\n",
    "__default_enddate = \"December.2014\"\n",
    "\n",
    "__default_startdate = \"January.2005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOWNLOAD METHOD\n",
    "\n",
    "\n",
    "def download_file(searchTerms, download_folder, url = url, username = username, \\\n",
    "                  dead_time = dead_time, path_to_chromedriver=path_to_chromedriver, enddate=__default_enddate):\n",
    "    while True:\n",
    "        endmonth,endyear = enddate.split(\".\")\n",
    "        \n",
    "        startmonth,startyear = __default_startdate.split(\".\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            __DRIVER = \"FF\" #  OP -opera\n",
    "\n",
    "            if __DRIVER==\"FF\":\n",
    "                #### FIREFOX OPTIONS\n",
    "                \n",
    "\n",
    "                profile = webdriver.FirefoxProfile()\n",
    "                profile.set_preference(\"browser.download.folderList\", 2)\n",
    "                profile.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "                profile.set_preference(\"browser.download.dir\", download_folder + r'/temp')\n",
    "                profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/x-zip-compressed\")\n",
    "                browser = webdriver.Firefox(executable_path = path_to_ffdriver,firefox_profile=profile)\n",
    "\n",
    "\n",
    "            elif __DRIVER==\"OP\":\n",
    "                ### CHROME/OPERA\n",
    "                \n",
    "\n",
    "                # chromeOptions = webdriver.ChromeOptions()\n",
    "                prefs = {\"download.default_directory\" : download_folder + r'/temp'}\n",
    "                # chromeOptions.add_argument('headless')\n",
    "                chromeOptions = webdriver.ChromeOptions()\n",
    "                # chromeOptions.add_argument(\"--window-size=1800,1000\")\n",
    "                # chromeOptions.add_argument(\"--disable-extensions\")\n",
    "                # chromeOptions.add_argument(\"--proxy-server='direct://'\")\n",
    "                # chromeOptions.add_argument(\"--proxy-bypass-list=*\")\n",
    "                # chromeOptions.add_argument(\"--start-maximized\")\n",
    "                # chromeOptions.add_argument('--headless')\n",
    "                # chromeOptions.add_argument('--disable-gpu')\n",
    "                # chromeOptions.add_argument('--disable-dev-shm-usage')\n",
    "                # chromeOptions.add_argument('--no-sandbox')\n",
    "                # chromeOptions.add_argument('--ignore-certificate-errors')\n",
    "                # chromeOptions.add_argument('no-sandbox')\n",
    "                chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "                browser = webdriver.Chrome(executable_path = path_to_chromedriver, options=chromeOptions)\n",
    "\n",
    "                        \n",
    "            print(\"scraping starts\")\n",
    "            browser.set_window_size(1800, 1000)\n",
    "            #browser.set_window_size(900, 500)\n",
    "            #Login\n",
    "            browser.get(url)\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"login in time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_id('username').send_keys(username)\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            browser.find_element_by_id('password').send_keys(password)\n",
    "            browser.find_element_by_xpath('//*[@id=\"loginform\"]/div[4]/button').click()\n",
    "            print(\"{} login in successfully\".format(username))\n",
    "            # Get Page Info\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"redirect to search page time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"searchTerms\"]').send_keys(searchTerms)\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            browser.find_element_by_xpath('//*[@id=\"mainSearch\"]').click()\n",
    "            # Sort by Date and narrow by some conditions\n",
    "            #publication type\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting publication type conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonpublicationtype\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            try:\n",
    "                browser.find_element_by_class_name('more').click()\n",
    "            except:\n",
    "                pass\n",
    "            while True:\n",
    "                try:\n",
    "                    for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Newswires & Press Releases')]\"):\n",
    "                        try:\n",
    "                            ele.click()\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            print(\"publication type is set\")\n",
    "            #source\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting source conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonsource\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            try:\n",
    "                # browser.find_element_by_xpath('//*[@id=\"refine\"]/ul[1]/li[7]/button').click()\n",
    "                browser.find_element_by_class_name('more').click()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Business Wire')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                #browser.find_element_by_text_link('The Associated Press').click()\n",
    "                #browser.find_elements_by_xpath(\"//*[contains(text(), 'My Button')]\").click()\n",
    "                print(\"source is set\")\n",
    "            except:\n",
    "                pass\n",
    "            # timeline start\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting timeline time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"refine\"]/button[2]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            if int(browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[1]/input').get_attribute('value').split('/')[-1]) <= 2001:\n",
    "                browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[1]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectyeartimeline\"]').click()\n",
    "                #browser.find_element_by_xpath('//*[@id=\"datepicker\"]/h3/div[2]/ol/li[33]/button').click()\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+startyear+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+startmonth+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[2]/td[3]/button').click()\n",
    "            # timeline end\n",
    "            if int(browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[2]/input').get_attribute('value').split('/')[-1]) >= 2019:\n",
    "                browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/div[2]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectyeartimeline\"]').click()\n",
    "                #for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '2014')]\"):\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+endyear+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                #for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'December')]\"):\n",
    "                for ele in browser.find_elements_by_xpath(\"//*[contains(text(), '\"+endmonth+\"')]\"):\n",
    "                    try:\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                #browser.find_element_by_xpath('//*[@id=\"selectmonthtimeline\"]').click()\n",
    "                #browser.find_element_by_xpath('//*[@id=\"datepicker\"]/h3/div[1]/ol/li[12]/button').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"datepicker\"]/table/tbody/tr[6]/td[2]/button').click()\n",
    "            # click ok\n",
    "            browser.find_element_by_xpath('//*[@id=\"refine\"]/div[2]/div[4]/button').click()\n",
    "            start_time = time.time()\n",
    "            print(\"time range is set\")\n",
    "            # subject\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"setting subject conditions timeout\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"podfiltersbuttonsubject\"]').click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            while True:\n",
    "                try:\n",
    "                    for ele in browser.find_elements_by_xpath(\"//*[contains(text(), 'Business News')]\"):\n",
    "                        try:\n",
    "                            ele.click()\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            print(\"subject is set\")\n",
    "\n",
    "            #sort by time\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"sorting by time time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[2]/li/div/button').click()\n",
    "                    break\n",
    "                except WebDriverException:\n",
    "                    time.sleep(1)\n",
    "            browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[2]/li/div/div/button[4]').click()\n",
    "            #N_temp = how many articles eg: News (10,000+)\n",
    "            start = time.time()\n",
    "            while True:\n",
    "                if time.time() - start > dead_time:\n",
    "                    print(\"get number of articles time out\")\n",
    "                    raise Exception()\n",
    "                try:\n",
    "                    #N_temp = browser.find_element_by_xpath('//*[@id=\"content\"]/header/h2/span').text\n",
    "                    N_temp = browser.find_element_by_xpath('/html/body/main/div/main/div[2]/div/div[2]/div[2]/form/div[2]/nav/ol/li[6]/a').text\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "            total_number = int(''.join(re.findall(r'[0-9]', N_temp)))\n",
    "            print(\"we'll scrape down {} files related to '{}'\".format(total_number, searchTerms))\n",
    "            total_page = int(np.ceil(total_number/10))\n",
    "            file_digit = len(str(total_page)) * 2 + 1\n",
    "            for page in range(1, total_page + 1):\n",
    "                time.sleep(2)\n",
    "                date = browser.find_element_by_xpath('//*[@id=\"content\"]/div[2]/form/div[2]/ol/li[1]/div/div[1]/dl/dd[4]/a').text\n",
    "                month, year = date.split(',')\n",
    "                month = month_d[month[:3]]\n",
    "                new_folder = download_folder + r'/{}/{}{}'.format(searchTerms, month.strip(), year.strip())\n",
    "                #new_folder = download_folder + r'\\{}-{}\\{}'.format( month.strip(), year.strip(),searchTerms)\n",
    "                # =============================================================================\n",
    "                #     If the file already exists. Go to next page.\n",
    "                # =============================================================================\n",
    "                if os.path.isfile(new_folder + '/'  + (str(page) + '_' + str(total_page)).zfill(file_digit) +  '.ZIP'):\n",
    "                #if os.path.isfile(download_folder + '/'  + (str(page) + '_' + str(total_page)).zfill(file_digit) +  '.ZIP'):\n",
    "\n",
    "                    print('exist: ' + str(page) + '_' + str(total_page) +  '.ZIP')\n",
    "                    if page < total_page:\n",
    "                        try:\n",
    "                            start_time = time.time()\n",
    "                            while True:\n",
    "                                if time.time() - start_time > dead_time:\n",
    "                                    raise Exception()\n",
    "                                WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.LINK_TEXT , str(page + 1))))\n",
    "                                browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                        except WebDriverException:\n",
    "                            time.sleep(3)\n",
    "                            continue\n",
    "                # =============================================================================\n",
    "                # Wait the all checkbox to be clickable\n",
    "                # =============================================================================\n",
    "                while True:\n",
    "                    print(\"here\")\n",
    "                    try:\n",
    "                        ele = browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input')\n",
    "                        print(ele)\n",
    "                        # if browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input').get_attribute('checked') != 'true':\n",
    "                        #     browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[1]/input').click()\n",
    "                        # print(ele.get_attribute('checked'))\n",
    "                        # if not ele.get_attribute('checked'):\n",
    "                        ele.click()\n",
    "                        break\n",
    "                    except WebDriverException:\n",
    "                        time.sleep(1)\n",
    "                # =============================================================================\n",
    "                #   Wait the IncludeAttachments button to be clickable.  otherwise re-click download buttom\n",
    "                # =============================================================================\n",
    "                # try:\n",
    "                #     start_time = time.time()\n",
    "                #     while True:\n",
    "                #         if time.time() - start_time > dead_time:\n",
    "                #             raise Exception()\n",
    "                #         elm = browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[4]/ul/li[3]/button')\n",
    "                #         elm.click()\n",
    "                # except WebDriverException:\n",
    "                #     pass\n",
    "                while True:\n",
    "                    try:\n",
    "                        browser.find_element_by_xpath('//*[@id=\"results-list-delivery-toolbar\"]/div/ul[1]/li[4]/ul/li[3]/button').click()\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    if time.time() - start_time > dead_time:\n",
    "                        raise Exception()\n",
    "                    try:\n",
    "                        browser.find_element_by_xpath('//*[@id=\"DocumentsOnly\"]').click()\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                browser.find_element_by_xpath('//*[@id=\"IncludeAttachments\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"Docx\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"SeparateFiles\"]').click()\n",
    "                browser.find_element_by_xpath('//*[@id=\"FileName\"]').clear()\n",
    "                browser.find_element_by_xpath('//*[@id=\"FileName\"]').send_keys((str(page) + '_' + str(total_page)).zfill(file_digit))\n",
    "                # =============================================================================\n",
    "                #     After downloading Close the pop up window. LexisNexis only allows 5 cocurrent windows\n",
    "                # =============================================================================\n",
    "                \n",
    "                before = browser.window_handles[0]\n",
    "                # browser.find_element_by_xpath('/html/body/aside/footer/ul/li[1]/input').click()\n",
    "                browser.find_element_by_xpath('/html/body/aside/footer/div/button[1]').click()\n",
    "                # print('here')\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    try:\n",
    "                        after = browser.window_handles[1]\n",
    "                        break\n",
    "                    except:\n",
    "                        time.sleep(1)\n",
    "                browser.switch_to.window(after)\n",
    "                start_time = time.time()\n",
    "                while True:\n",
    "                    if time.time() - start_time > dead_time:\n",
    "                        raise Exception()\n",
    "                    if  browser.find_elements_by_link_text((str(page) + '_' + str(total_page)).zfill(file_digit)):\n",
    "                        break\n",
    "                \n",
    "                ### CHECK DOWNLOAD COMPLETED BEFORE WE CLOSE DOWNLOAD WINDOW\n",
    "                start_time = time.time()\n",
    "                ### wait maximum 30s for download\n",
    "                while time.time() - start_time < 30:\n",
    "                    try:\n",
    "                        if \"Delivery Complete\" in browser.find_element_by_xpath('/html/body/main/div/div[2]/section/h1').text:\n",
    "                            print(\"-> Closing the Download Window...\")\n",
    "                            time.sleep(1)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"-> Waiting for Download to be complete...\")\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(\"Exception @ waiting download to complete -->\",e)\n",
    "                        time.sleep(1)\n",
    "                    finally:\n",
    "                        time.sleep(1)\n",
    "        \n",
    "                        \n",
    "                #time.sleep(100)\n",
    "                \n",
    "                browser.close()\n",
    "                browser.switch_to.window(before)\n",
    "                print(browser.title)\n",
    "                time.sleep(2)\n",
    "                old_folder = download_folder + r'/temp'\n",
    "                os.chdir(old_folder)\n",
    "                if not os.path.isdir(new_folder):\n",
    "                    os.makedirs(new_folder)\n",
    "                for f in os.listdir():\n",
    "                    shutil.move(old_folder + r'/{}'.format(f), new_folder + r'/{}'.format(f))\n",
    "                print('finishing page' + str(page) + '_' + str(total_page)  )\n",
    "                # =============================================================================\n",
    "                #     Go to the next page. Have to check the next page link is clickable\n",
    "                # =============================================================================\n",
    "                if page < total_page:\n",
    "                    try:\n",
    "                        browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                        start_time = time.time()\n",
    "                        while True:\n",
    "                            if time.time() - start_time > dead_time:\n",
    "                                raise Exception()\n",
    "                            browser.find_element_by_link_text(str(page + 1)).click()\n",
    "                    except WebDriverException:\n",
    "                        time.sleep(3)\n",
    "                        pass\n",
    "                else:\n",
    "                    print('FINISHED!')\n",
    "                    #sys.exit()\n",
    "                    return 7\n",
    "                # except Exception:\n",
    "                #     print('restarting')\n",
    "                #     continue\n",
    "            print('Finished')\n",
    "            return 7\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Main exception->\",e)\n",
    "            print(traceback.format_exc())\n",
    "            print(\"restarting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITIES AND HELPERS\n",
    "\n",
    "\n",
    "\n",
    "def unzip(download_folder):\n",
    "    if not os.path.exists(download_folder + '/' + 'unzipped'):\n",
    "        os.makedirs(download_folder + '/' + 'unzipped')\n",
    "    for filename in os.listdir(download_folder):\n",
    "        if not filename.endswith('.ZIP'):\n",
    "            continue\n",
    "        zip_ref = zipfile.ZipFile(download_folder +  '/' + filename, 'r')\n",
    "        zip_ref.extractall(download_folder + '/' + 'unzipped')\n",
    "        if len(zip_ref.namelist()) != 11:\n",
    "            print('missing document at ' + filename)\n",
    "        zip_ref.close()\n",
    "        print('unzipping ' + filename)\n",
    "\n",
    "\n",
    "def create_index(download_folder, searchTerms):\n",
    "    def get_docx_text(path):\n",
    "        WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "        PARA = WORD_NAMESPACE + 'p'\n",
    "        TEXT = WORD_NAMESPACE + 't'\n",
    "        \"\"\"\n",
    "        Take the path of a docx file as argument, return the text in unicode.\n",
    "        \"\"\"\n",
    "        document = zipfile.ZipFile(path)\n",
    "        xml_content = document.read('word/document.xml')\n",
    "        document.close()\n",
    "        tree = XML(xml_content)\n",
    "\n",
    "        paragraphs = []\n",
    "        for paragraph in tree.getiterator(PARA):\n",
    "            texts = [node.text\n",
    "                     for node in paragraph.getiterator(TEXT)\n",
    "                     if node.text]\n",
    "            if texts:\n",
    "                paragraphs.append(''.join(texts))\n",
    "\n",
    "        return '\\n\\n'.join(paragraphs)\n",
    "    def get_docx_hyperlink(path):\n",
    "        document = Document(path)\n",
    "        rels = document.part.rels\n",
    "        link = []\n",
    "        for rel in rels:\n",
    "            if rels[rel].reltype == RT.HYPERLINK:\n",
    "                link.append(rels[rel]._target)\n",
    "        return pd.Series(link)\n",
    "    def find_between(s, first, last):\n",
    "        list = []\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    start = s.index( first ) + len( first )\n",
    "                    end = s.index( last, start )\n",
    "                    list.append( s[start:end])\n",
    "                    s = s.replace(first + s[start:end] + last,'')\n",
    "                except:\n",
    "                    break\n",
    "            return list\n",
    "        except ValueError:\n",
    "            return \"\"\n",
    "\n",
    "    index = pd.DataFrame(({'Title':{},'Link':{}}))\n",
    "    for filename in os.listdir(download_folder + '/' + 'unzipped'):\n",
    "        if filename.find(\"doclist\") == -1:\n",
    "            continue\n",
    "        text = get_docx_text(download_folder + '/' + 'unzipped/' + filename)\n",
    "        link = get_docx_hyperlink(download_folder + '/' + 'unzipped/' + filename).loc[0]\n",
    "        content = '<start>' + re.sub(r'.*Documents \\(\\d*\\)', '',text.replace('\\n',' ')).replace(\\\n",
    "              'Client/Matter: -None-  Search Terms: '+ searchTerms + '  Search Type: Terms and Connectors   Narrowed by:   Content Type  Narrowed by  News  -None-',\\\n",
    "              '<end><start>')\n",
    "        content_list = pd.Series(find_between(content, '<start>', '<end>'))\n",
    "        content_list = content_list.str[5:]\n",
    "        index = index.append(pd.DataFrame({'Title':content_list,'Link':link}),ignore_index = True)\n",
    "    index = index.reset_index()\n",
    "    index['index'] = index.index + 1\n",
    "    index.to_csv(download_folder + '/index.csv', index=False)\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX AND SCRIPT SUPERVISOR HELPERS\n",
    "\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "# SET CONFIG VARIABLES\n",
    "__download_folder = os.path.join(root,\"download\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_last_download_date(__searchterm):\n",
    "    # check if folder exists\n",
    "    if __searchterm in os.listdir(__download_folder):\n",
    "        __folder_searchterm = os.path.join(__download_folder,__searchterm)\n",
    "\n",
    "        already_downloaded = os.listdir(__folder_searchterm)\n",
    "\n",
    "        if len(already_downloaded)==0:\n",
    "            __enddate = __default_enddate\n",
    "\n",
    "        else:\n",
    "\n",
    "            # sort on datetime\n",
    "            already_downloaded = sorted(already_downloaded, key=dateutil.parser.parse)\n",
    "\n",
    "\n",
    "            latest = already_downloaded[0]\n",
    "\n",
    "\n",
    "            # empty the latest folder\n",
    "            __folder_latest = os.path.join(__folder_searchterm,latest)\n",
    "\n",
    "            #crawl subdirs in side latest folder and delete\n",
    "            for subfolder in os.listdir(__folder_latest):\n",
    "                this_path = os.path.join(__folder_latest,subfolder)\n",
    "                print(\"DELETING --->\",this_path)\n",
    "                if os.path.isdir(this_path):\n",
    "                    shutil.rmtree(__folder_latest)\n",
    "                else:\n",
    "                    os.remove(this_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            __enddate = dateutil.parser.parse(latest).strftime(\"%B.%Y\")\n",
    "\n",
    "    else:\n",
    "        __enddate = __default_enddate\n",
    "        \n",
    "    return __enddate\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING FULL DOWNLOAD TILL ---> December.2014\n",
      "\n",
      "\n",
      "scraping starts\n",
      "junhuihe login in successfully\n",
      "publication type is set\n",
      "source is set\n",
      "time range is set\n",
      "subject is set\n",
      "we'll scrape down 609 files related to 'ticker(ORCL)'\n",
      "here\n",
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"a3856be1-69e3-46ea-90da-4f7813e8ab17\", element=\"0dec682c-93d2-4526-b40d-7f9ecfa6f465\")>\n",
      "-> Closing the Download Window...\n",
      "6,082 results for ticker(ORCL) (narrowed)\n",
      "finishing page1_61\n",
      "here\n",
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"a3856be1-69e3-46ea-90da-4f7813e8ab17\", element=\"6f807273-c7d1-4fce-b6f0-b8045001ff6a\")>\n",
      "-> Closing the Download Window...\n",
      "6,082 results for ticker(ORCL) (narrowed)\n",
      "finishing page2_61\n",
      "here\n",
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"a3856be1-69e3-46ea-90da-4f7813e8ab17\", element=\"ce051c00-7207-4e62-b138-df023648581f\")>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-637ffe59a4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchTerms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchTerms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__download_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menddate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__enddate\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# unzip()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8726f90543a3>\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(searchTerms, download_folder, url, username, dead_time, path_to_chromedriver, enddate)\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdead_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                     \u001b[0;32mif\u001b[0m  \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_link_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sign In'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINK_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element_by_partial_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[1;32m   1006\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             'value': value})['value'] or []\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             return self.request_encode_body(\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/shuyi/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### MAIN\n",
    "\n",
    "\n",
    "try:\n",
    "    if \"SEARCHTERM\" in os.environ:\n",
    "        searchTermsList = [os.environ[\"SEARCHTERM\"]]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Have you suppied ENVIRONMENT VAR -> SEARCHTERM\")\n",
    "    #exit(0)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for searchTerms in searchTermsList:\n",
    "        \n",
    "        __enddate = get_last_download_date(searchTerms)\n",
    "        \n",
    "        if(__enddate==__default_enddate):\n",
    "            print(\"\\nSTARTING FULL DOWNLOAD TILL ---> %s\\n\\n\" % __enddate )\n",
    "        else:\n",
    "            print(\"\\nRESUMING TILL END DATE --> %s\\n\\n\" % __enddate)\n",
    "            \n",
    "        \n",
    "\n",
    "        val = download_file(searchTerms = searchTerms, download_folder = __download_folder, enddate=__enddate )\n",
    "        \n",
    "        ## SAVE PROGRESS IF FINISHED\n",
    "        if val==7:\n",
    "            with open(\"done.txt\",'a+') as g:\n",
    "                g.write(searchTerms+\"\\n\")\n",
    "        \n",
    "    # unzip()\n",
    "    # create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
